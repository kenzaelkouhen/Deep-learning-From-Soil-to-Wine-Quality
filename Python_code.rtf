{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Light;\f2\fswiss\fcharset0 Helvetica-Bold;
\f3\fmodern\fcharset0 Courier;\f4\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;\red25\green25\blue25;
\red255\green255\blue255;\red25\green25\blue25;\red0\green0\blue0;\red25\green25\blue25;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000\c0;\cssrgb\c0\c0\c0;\cssrgb\c12955\c12955\c12939;
\cssrgb\c100000\c100000\c100000;\cssrgb\c12941\c12941\c12941;\cssrgb\c0\c0\c0\c87059;\cssrgb\c12970\c12970\c12937;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh15700\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \

\f1 \
\pard\pardeftab720\sa140\partightenfactor0

\f2\b \cf0 \cb2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 1. Merging the complete DF
\f1\b0 \
\pard\pardeftab720\partightenfactor0
\cf0 import glob\
import pandas as pd\
import numpy as np\
import math\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 from\cf4 \strokec4  matplotlib \cf4 \strokec4 import\cf4 \strokec4  pyplot \cf4 \strokec4 as\cf4 \strokec4  plt\
\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec3 all_dataframes =  [ ]\
all_dataframes.append(pd.read_csv('soil_analysis.csv'))\
all_dataframes.append(pd.read_csv('leaf_analysis.csv'))\
all_dataframes.append(pd.read_csv('petiole_analysis.csv'))\
\
\
\pard\pardeftab720\sa140\partightenfactor0

\f2\b \cf0 2. Rename column's name
\f1\b0 \
\pard\pardeftab720\partightenfactor0
\cf0 for df in all_dataframes:\
    print(df.columns.values)\cb5 \strokec3 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb1 \strokec6 i = 1\
for df in all_dataframes:\
    m = \{\}\
    for name in df.columns.values[6:]:\
        m[name] = str(name+str(i))\
    i += 1\
    all_dataframes[i-2] = df.rename(columns=m)\
\
for df in all_dataframes:\
    print(df.columns.values)
\f3\fs26 \
\

\f1\fs24 df = all_dataframes[0]\
df = pd.merge(df, all_dataframes[1], how='outer', on=['ID Company', 'ID Lot', 'Nation', 'Province', 'Place', 'Year'])\
df = pd.merge(df, all_dataframes[2], how='outer', on=['ID Company', 'ID Lot', 'Nation', 'Province', 'Place', 'Year'])\
\
df.to_csv('complete_dataset.csv')
\f3\fs26 \
\
\
\
\pard\pardeftab720\partightenfactor0

\f2\b\fs24 \cf3 \cb2 \strokec7 2. Remove records having values of only 1 phase out of the three (soil/leaf/petiole)
\f1\b0 \cf6 \cb1 \strokec6 \
\
features = df.columns.values\
\
features_soil = features[6:30]\
features_leaf = features[30:41]\
features_petiole = features[41:]\
\
\pard\pardeftab720\partightenfactor0
\cf6 def check_empty(sample, features):\
    for feature in features:\
        if not math.isnan(sample[feature]):\
            return 0\
    return 1\
\
to_drop = []\
for index, row in df.iterrows():\
    if check_empty(row, features_soil) + check_empty(row, features_leaf) + check_empty(row, features_petiole) >= 2:\
        to_drop.append(index)\
df = df.drop(to_drop)\

\f3\fs26 \
\
\pard\pardeftab720\sa140\partightenfactor0

\f2\b\fs24 \cf0 \cb2 \strokec3 3.1 Integration height values
\f1\b0 \
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 ita_h = pd.read_csv("additional_datasets/italy_heights.csv")\
slo_h = pd.read_csv("additional_datasets/slovenia_heights.csv")\
cro_h = pd.read_csv("additional_datasets/croatia_heights.csv")\
spa_h = pd.read_csv("additional_datasets/spagna_heights.csv")\
\
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 ita_h['HEIGHT'] = ita_h['HEIGHT'].str.replace(',', '.').astype(float)\
\
heights = []\
for index, row in df.iterrows():\
    if row["Nation"] == "Italia":\
        i = ita_h.loc[ita_h["NAME"] == row["Place"]].index.values[0]\
        heights.append(ita_h.at[i, "HEIGHT"])\
    elif row["Nation"] == "Slovenia":\
        i = slo_h.loc[slo_h["NAME"] == row["Place"]].index.values[0]\
        heights.append(slo_h.at[i, "HEIGHT"])\
    elif row["Nation"] == "Croazia":\
        i = cro_h.loc[cro_h["NAME"] == row["Place"]].index.values[0]\
        heights.append(cro_h.at[i, "HEIGHT"])\
    elif row["Nation"] == "Spagna":\
        i = spa_h.loc[spa_h["NAME"] == row["Place"]].index.values[0]\
        heights.append(spa_h.at[i, "HEIGHT"])\
    else:\
        print("Error: Nation not allowed")\
\
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 if "Height" not in df.columns.values.tolist():\
    df.insert(6, "Height", heights, True)\
\
\
\pard\pardeftab720\sa140\partightenfactor0

\f2\b \cf0 3.2 Integration temperature and humidity
\f1\b0 \
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 temp_hum = pd.read_csv("temperature&humidity/complete_temp_hum.csv")\
temp_hum = temp_hum.drop(temp_hum.columns.values[0], axis = 1)\
\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 phase2 \cf4 \strokec4 =\cf4 \strokec4  temp_hum\cf4 \strokec4 .\cf4 \strokec4 loc[temp_hum["Phase"] \cf4 \strokec4 ==\cf4 \strokec4  2]\cf4 \strokec4 .\cf4 \strokec4 copy()\
phase2\cf4 \strokec4 .\cf4 \strokec4 rename(columns \cf4 \strokec4 =\cf4 \strokec4  \{"T avg [\uc0\u730 C]": "T avg 2", "T min [\u730 C]": "T min 2", "T max [\u730 C]": "T max 2", "Humidity": "Humidity2"\}, inplace \cf4 \strokec4 =\cf4 \strokec4  \cf4 \strokec4 True\cf4 \strokec4 )\
phase2 \cf4 \strokec4 =\cf4 \strokec4  phase2\cf4 \strokec4 .\cf4 \strokec4 drop("Phase", axis \cf4 \strokec4 =\cf4 \strokec4  1)\
\
phase3 \cf4 \strokec4 =\cf4 \strokec4  temp_hum\cf4 \strokec4 .\cf4 \strokec4 loc[temp_hum["Phase"] \cf4 \strokec4 ==\cf4 \strokec4  3]\cf4 \strokec4 .\cf4 \strokec4 copy()\
phase3\cf4 \strokec4 .\cf4 \strokec4 rename(columns \cf4 \strokec4 =\cf4 \strokec4  \{"T avg [\uc0\u730 C]": "T avg 3", "T min [\u730 C]": "T min 3", "T max [\u730 C]": "T max 3", "Humidity": "Humidity3"\}, inplace \cf4 \strokec4 =\cf4 \strokec4  \cf4 \strokec4 True\cf4 \strokec4 )\
phase3 \cf4 \strokec4 =\cf4 \strokec4  phase3\cf4 \strokec4 .\cf4 \strokec4 drop("Phase", axis \cf4 \strokec4 =\cf4 \strokec4  1)\
\
temp_hum \cf4 \strokec4 =\cf4 \strokec4  pd\cf4 \strokec4 .\cf4 \strokec4 merge(phase2, phase3, how \cf4 \strokec4 =\cf4 \strokec4  'outer', on \cf4 \strokec4 =\cf4 \strokec4  ["Province", "Year"])
\f3\fs26 \cf6 \cb1 \strokec6 \
\

\f1\fs24 \cf4 \cb2 \strokec4 df \cf4 \strokec4 =\cf4 \strokec4  pd\cf4 \strokec4 .\cf4 \strokec4 merge(df, temp_hum, how \cf4 \strokec4 =\cf4 \strokec4  "left", on \cf4 \strokec4 =\cf4 \strokec4  ["Province", "Year"])\
df\cf4 \strokec4 .\cf4 \strokec4 to_csv('complete_dataset.csv')\
\
\
\pard\pardeftab720\sa140\partightenfactor0

\f2\b \cf0 \strokec3 3.3 Integration coordinates
\f1\b0 \
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 coo = pd.read_csv("geo_coords.csv", sep = "\\t")\
coo = coo.rename(\{"City" : "Place"\}, axis = 1)\
df = pd.merge(df, coo, how="left", on="Place")\
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 df.to_csv('complete_dataset.csv')
\f3\fs28 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0

\fs26 \cf6 \strokec6 \
\pard\pardeftab720\partightenfactor0

\f2\b\fs24 \cf3 \cb2 \strokec7 4. Data cleaning: fix the '<x' and '>x' data\
\
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf4 \strokec4 feature \cf4 \strokec4 =\cf4 \strokec4  "Cu3"\
less \cf4 \strokec4 =\cf4 \strokec4  []      \cf4 \strokec4 #elements presenting '< x'\cf4 \strokec4 \
great \cf4 \strokec4 =\cf4 \strokec4  []     \cf4 \strokec4 #elements presenting '> x'\cf4 \strokec4 \
normal \cf4 \strokec4 =\cf4 \strokec4  []    \cf4 \strokec4 #legit elements (Nan are not considered here)\cf4 \strokec4 \
\
\cf4 \strokec4 for\cf4 \strokec4  val \cf4 \strokec4 in\cf4 \strokec4  df[feature]:\
    \cf4 \strokec4 if\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '<':\
        temp \cf4 \strokec4 =\cf4 \strokec4  str(val)[1:]\
        temp \cf4 \strokec4 =\cf4 \strokec4  float(temp\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
        \cf4 \strokec4 if\cf4 \strokec4  temp \cf4 \strokec4 not\cf4 \strokec4  \cf4 \strokec4 in\cf4 \strokec4  less:\
            less\cf4 \strokec4 .\cf4 \strokec4 append(temp)\
            print("less than "\cf4 \strokec4 +\cf4 \strokec4 str(less[\cf4 \strokec4 -\cf4 \strokec4 1]))\
    \cf4 \strokec4 elif\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '>':\
        temp \cf4 \strokec4 =\cf4 \strokec4  str(val)[1:]\
        temp \cf4 \strokec4 =\cf4 \strokec4  float(temp\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
        \cf4 \strokec4 if\cf4 \strokec4  temp \cf4 \strokec4 not\cf4 \strokec4  \cf4 \strokec4 in\cf4 \strokec4  great:\
            great\cf4 \strokec4 .\cf4 \strokec4 append(temp)\
            print("greater than "\cf4 \strokec4 +\cf4 \strokec4 str(great[\cf4 \strokec4 -\cf4 \strokec4 1]))\
    \cf4 \strokec4 elif\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  math\cf4 \strokec4 .\cf4 \strokec4 isnan(float(str(val)\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))):\
        temp \cf4 \strokec4 =\cf4 \strokec4  float(str(val)\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
        normal\cf4 \strokec4 .\cf4 \strokec4 append(temp)\
\
plt\cf4 \strokec4 .\cf4 \strokec4 plot(normal)\
print("MIN = "\cf4 \strokec4 +\cf4 \strokec4 str(min(normal)))\
print("MAX = "\cf4 \strokec4 +\cf4 \strokec4 str(max(normal)))\
\
features \cf4 \strokec4 =\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 columns\cf4 \strokec4 .\cf4 \strokec4 values[7:]\
types \cf4 \strokec4 =\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 dtypes[7:]\
\
print("Max values of the affected columns")\
\
i \cf4 \strokec4 =\cf4 \strokec4  0\
\cf4 \strokec4 for\cf4 \strokec4  feature \cf4 \strokec4 in\cf4 \strokec4  features:\
    \cf4 \strokec4 #only columns with dtype=object need to be fixed\cf4 \strokec4 \
    \cf4 \strokec4 if\cf4 \strokec4  types[i] \cf4 \strokec4 !=\cf4 \strokec4  "object":\
        i \cf4 \strokec4 +=\cf4 \strokec4  1\
        \cf4 \strokec4 continue\cf4 \strokec4 \
    new_col \cf4 \strokec4 =\cf4 \strokec4  []\
    \
    \cf4 \strokec4 #find the max value\cf4 \strokec4 \
    m \cf4 \strokec4 =\cf4 \strokec4  0\
    \cf4 \strokec4 for\cf4 \strokec4  val \cf4 \strokec4 in\cf4 \strokec4  df[feature]:\
        \cf4 \strokec4 if\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '<':\
            \cf4 \strokec4 continue\cf4 \strokec4 \
        \cf4 \strokec4 elif\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '>':\
            temp \cf4 \strokec4 =\cf4 \strokec4  temp \cf4 \strokec4 =\cf4 \strokec4  str(val)[1:]\
            temp \cf4 \strokec4 =\cf4 \strokec4  float(temp\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
            m \cf4 \strokec4 =\cf4 \strokec4  max(m, temp)\
        \cf4 \strokec4 else\cf4 \strokec4 :\
            temp \cf4 \strokec4 =\cf4 \strokec4  float(str(val)\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
            m \cf4 \strokec4 =\cf4 \strokec4  max(m, temp)\
    print(feature\cf4 \strokec4 +\cf4 \strokec4 "    "\cf4 \strokec4 +\cf4 \strokec4 str(m))\
    \
    \cf4 \strokec4 #compose the new/clean column of values\cf4 \strokec4 \
    \cf4 \strokec4 for\cf4 \strokec4  val \cf4 \strokec4 in\cf4 \strokec4  df[feature]:\
        temp \cf4 \strokec4 =\cf4 \strokec4  val\
        \cf4 \strokec4 if\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '<':\
            temp \cf4 \strokec4 =\cf4 \strokec4  0.0\
        \cf4 \strokec4 elif\cf4 \strokec4  str(val)[0] \cf4 \strokec4 ==\cf4 \strokec4  '>':\
            temp \cf4 \strokec4 =\cf4 \strokec4  m\
        \cf4 \strokec4 else\cf4 \strokec4 :\
            temp \cf4 \strokec4 =\cf4 \strokec4  float(str(val)\cf4 \strokec4 .\cf4 \strokec4 replace(',', '.'))\
        new_col\cf4 \strokec4 .\cf4 \strokec4 append(temp)\
    \
    \cf4 \strokec4 #replace old column with the clean one\cf4 \strokec4 \
    df[feature] \cf4 \strokec4 =\cf4 \strokec4  new_col\
    i \cf4 \strokec4 +=\cf4 \strokec4  1\
\
df\cf4 \strokec4 .\cf4 \strokec4 to_csv('complete_dataset.csv')\
\
\
\pard\pardeftab720\sa140\partightenfactor0

\f2\b \cf0 \strokec3 Handling sparse missing values\
Let's count first the number of missing values in the current version of the dataset
\f1\b0 \
\pard\pardeftab720\partightenfactor0
\cf0 features = df.columns.values\
features_soil = features[7:31]\
features_leaf = features[31:42]\
features_petiole = features[42:53]\
\
\pard\pardeftab720\qr\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 def\cf4 \strokec4  count_missing(record, features, miss):\
    c \cf4 \strokec4 =\cf4 \strokec4  0\
    \cf4 \strokec4 for\cf4 \strokec4  feature \cf4 \strokec4 in\cf4 \strokec4  features:\
        \cf4 \strokec4 if\cf4 \strokec4  math\cf4 \strokec4 .\cf4 \strokec4 isnan(record[feature]):\
            miss[feature] \cf4 \strokec4 +=\cf4 \strokec4  1\
            c \cf4 \strokec4 +=\cf4 \strokec4  1\
    \cf4 \strokec4 return\cf4 \strokec4  c\
\
miss \cf4 \strokec4 =\cf4 \strokec4  \{\}\
\cf4 \strokec4 for\cf4 \strokec4  feature \cf4 \strokec4 in\cf4 \strokec4  features[7:53]:\
    miss[feature] \cf4 \strokec4 =\cf4 \strokec4  0\
\
\cf4 \strokec4 for\cf4 \strokec4  index, row \cf4 \strokec4 in\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 iterrows():\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_soil):\
        count_missing(row, features_soil, miss)\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_leaf):\
        count_missing(row, features_leaf, miss)\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_petiole):\
        count_missing(row, features_petiole, miss)\
\
print("Total number of rows = " \cf4 \strokec4 +\cf4 \strokec4  str(df\cf4 \strokec4 .\cf4 \strokec4 shape[0]))\

\f3\fs26 \cf6 \cb1 \strokec6 \

\f1\fs24 \cf4 \cb2 \strokec4 plt\cf4 \strokec4 .\cf4 \strokec4 figure(figsize\cf4 \strokec4 =\cf4 \strokec4 (20,6))\
plt\cf4 \strokec4 .\cf4 \strokec4 bar(miss\cf4 \strokec4 .\cf4 \strokec4 keys(), list(miss\cf4 \strokec4 .\cf4 \strokec4 values()), align\cf4 \strokec4 =\cf4 \strokec4 'center')\
plt\cf4 \strokec4 .\cf4 \strokec4 xticks(rotation\cf4 \strokec4 =\cf4 \strokec4 90)\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 #plt.xticks(range(len(miss)), list(miss.keys()))\cf4 \strokec4 \
plt\cf4 \strokec4 .\cf4 \strokec4 show\
\
p1 \cf4 \strokec4 =\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 filter(items \cf4 \strokec4 =\cf4 \strokec4  features_soil, axis \cf4 \strokec4 =\cf4 \strokec4  1)\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 for\cf4 \strokec4  index, row \cf4 \strokec4 in\cf4 \strokec4  p1\cf4 \strokec4 .\cf4 \strokec4 iterrows():\
    \cf4 \strokec4 if\cf4 \strokec4  check_empty(row, p1\cf4 \strokec4 .\cf4 \strokec4 columns\cf4 \strokec4 .\cf4 \strokec4 values):\
        p1 \cf4 \strokec4 =\cf4 \strokec4  p1\cf4 \strokec4 .\cf4 \strokec4 drop(index)\
\
\cf4 \strokec4 from\cf4 \strokec4  sklearn.impute \cf4 \strokec4 import\cf4 \strokec4  KNNImputer\
imputer \cf4 \strokec4 =\cf4 \strokec4  KNNImputer(n_neighbors\cf4 \strokec4 =\cf4 \strokec4 4)\
p1 \cf4 \strokec4 =\cf4 \strokec4  imputer\cf4 \strokec4 .\cf4 \strokec4 fit_transform(p1)\
p1 \cf4 \strokec4 =\cf4 \strokec4  pd\cf4 \strokec4 .\cf4 \strokec4 DataFrame\cf4 \strokec4 .\cf4 \strokec4 from_records(p1, columns \cf4 \strokec4 =\cf4 \strokec4  features_soil)\

\f3\fs26 \cf6 \cb1 \strokec6 \

\f1\fs24 \cf4 \cb2 \strokec4 \
p1_original \cf4 \strokec4 =\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 filter(items \cf4 \strokec4 =\cf4 \strokec4  features_soil, axis \cf4 \strokec4 =\cf4 \strokec4  1)\
p1_final \cf4 \strokec4 =\cf4 \strokec4  []\
\
i \cf4 \strokec4 =\cf4 \strokec4  0\
\cf4 \strokec4 for\cf4 \strokec4  index, row \cf4 \strokec4 in\cf4 \strokec4  p1_original\cf4 \strokec4 .\cf4 \strokec4 iterrows():\
    \cf4 \strokec4 if\cf4 \strokec4  check_empty(row, p1_original\cf4 \strokec4 .\cf4 \strokec4 columns\cf4 \strokec4 .\cf4 \strokec4 values):\
        p1_final\cf4 \strokec4 .\cf4 \strokec4 append(row)\
    \cf4 \strokec4 else\cf4 \strokec4 :\
        p1_final\cf4 \strokec4 .\cf4 \strokec4 append(p1\cf4 \strokec4 .\cf4 \strokec4 iloc[i]\cf4 \strokec4 .\cf4 \strokec4 copy())\
        i \cf4 \strokec4 +=\cf4 \strokec4  1\
p1_final \cf4 \strokec4 =\cf4 \strokec4  pd\cf4 \strokec4 .\cf4 \strokec4 DataFrame\cf4 \strokec4 .\cf4 \strokec4 from_records(p1_final)
\f3\fs26 \cf6 \cb1 \strokec6 \

\f1\fs24 \cf4 \cb2 \strokec4 \
\cf4 \strokec4 for\cf4 \strokec4  c \cf4 \strokec4 in\cf4 \strokec4  p1_final\cf4 \strokec4 .\cf4 \strokec4 columns:\
    df[c] \cf4 \strokec4 =\cf4 \strokec4  p1_final[c]\
\cf4 \strokec4 def\cf4 \strokec4  count_missing(record, features, miss):\
    c \cf4 \strokec4 =\cf4 \strokec4  0\
    \cf4 \strokec4 for\cf4 \strokec4  feature \cf4 \strokec4 in\cf4 \strokec4  features:\
        \cf4 \strokec4 if\cf4 \strokec4  math\cf4 \strokec4 .\cf4 \strokec4 isnan(record[feature]):\
            miss[feature] \cf4 \strokec4 +=\cf4 \strokec4  1\
            c \cf4 \strokec4 +=\cf4 \strokec4  1\
    \cf4 \strokec4 return\cf4 \strokec4  c\
\
miss \cf4 \strokec4 =\cf4 \strokec4  \{\}\
\cf4 \strokec4 for\cf4 \strokec4  feature \cf4 \strokec4 in\cf4 \strokec4  features[7:53]:\
    miss[feature] \cf4 \strokec4 =\cf4 \strokec4  0\
\
\cf4 \strokec4 for\cf4 \strokec4  index, row \cf4 \strokec4 in\cf4 \strokec4  df\cf4 \strokec4 .\cf4 \strokec4 iterrows():\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_soil):\
        count_missing(row, features_soil, miss)\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_leaf):\
        count_missing(row, features_leaf, miss)\
    \cf4 \strokec4 if\cf4 \strokec4  \cf4 \strokec4 not\cf4 \strokec4  check_empty(row, features_petiole):\
        count_missing(row, features_petiole, miss)\
\
print("Total number of rows = " \cf4 \strokec4 +\cf4 \strokec4  str(df\cf4 \strokec4 .\cf4 \strokec4 shape[0]))\
\
plt\cf4 \strokec4 .\cf4 \strokec4 figure(figsize\cf4 \strokec4 =\cf4 \strokec4 (20,6))\
plt\cf4 \strokec4 .\cf4 \strokec4 bar(miss\cf4 \strokec4 .\cf4 \strokec4 keys(), list(miss\cf4 \strokec4 .\cf4 \strokec4 values()), align\cf4 \strokec4 =\cf4 \strokec4 'center')\
plt\cf4 \strokec4 .\cf4 \strokec4 xticks(rotation\cf4 \strokec4 =\cf4 \strokec4 90)\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 #plt.xticks(range(len(miss)), list(miss.keys()))\cf4 \strokec4 \
plt\cf4 \strokec4 .\cf8 \strokec8 show\
\
\pard\pardeftab720\partightenfactor0
\cf4 \strokec4 df\cf4 \strokec4 .\cf4 \strokec4 to_csv('complete_dataset.csv')\

\f3\fs26 \cf6 \cb1 \strokec6 \
\
\

\f1\fs24 \cf4 \cb2 \strokec4 \
\

\f3\fs26 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\partightenfactor0

\fs28 \cf0 \strokec3 \
\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \cb2 \strokec3 \
\pard\pardeftab720\partightenfactor0

\f3\fs26 \cf6 \cb1 \strokec6 \
\
\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \cb5 \strokec3 \
\

\f3\fs28 \

\f4 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0

\f3\fs26 \cf6 \strokec6 \
\pard\pardeftab720\partightenfactor0
\cf6 \
\pard\pardeftab720\partightenfactor0

\fs28 \cf0 \strokec3 \
}